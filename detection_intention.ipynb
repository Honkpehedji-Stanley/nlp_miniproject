{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee25b6d1",
   "metadata": {
    "id": "ee25b6d1"
   },
   "source": [
    "# Detection d'Intention avec CamemBERT (Transformers)\n",
    "\n",
    "**Notebook optimise pour Google Colab GPU avec Transformers**\n",
    "\n",
    "Ce notebook utilise CamemBERT pour :\n",
    "1. Classification d'intent (TRIP, NOT_TRIP, UNKNOWN, NOT_FRENCH)\n",
    "2. Named Entity Recognition (Departure, Destination)\n",
    "\n",
    "**Ameliorations par rapport au baseline TF-IDF** :\n",
    "- Comprehension semantique profonde du texte\n",
    "- Detection precise des langues etrangeres\n",
    "- NER contextuel (pas juste un gazetteer)\n",
    "- Fine-tuning sur donnees francaises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c497b897",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c497b897",
    "outputId": "b314f33d-c070-4067-a1b1-6978e9d6d625"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook: Travel Order Resolver (CPU-optimized demo/full)\n"
     ]
    }
   ],
   "source": [
    "# Verification GPU et installation des dependances\n",
    "import torch\n",
    "\n",
    "print('='*70)\n",
    "print('DETECTION INTENTION - Transformers + CamemBERT')\n",
    "print('='*70)\n",
    "\n",
    "print(f'\\nPyTorch version: {torch.__version__}')\n",
    "print(f'CUDA disponible: {torch.cuda.is_available()}')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'Memoire GPU: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB')\n",
    "else:\n",
    "    print('ATTENTION: Pas de GPU detecte!')\n",
    "    print('Allez dans Runtime > Change runtime type > GPU')\n",
    "\n",
    "# Installation des packages Transformers\n",
    "!pip install -q transformers datasets evaluate seqeval accelerate scikit-learn langdetect\n",
    "print('\\nInstallation terminee!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9c9b9f",
   "metadata": {
    "id": "3a9c9b9f"
   },
   "source": [
    "## Montage Google Drive et desactivation WandB\n",
    "\n",
    "Monte Google Drive pour acceder aux datasets et desactive WandB (tracking non necessaire)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fffb57",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "84fffb57",
    "outputId": "cddd7c4a-8c66-45ca-e60c-0caf51330604"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "Working dir: /content/drive/MyDrive/dataset\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "# Monter Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Desactiver WandB\n",
    "os.environ['WANDB_DISABLED'] = 'true'\n",
    "\n",
    "# Chemins\n",
    "workdir = '/content/drive/MyDrive/dataset'\n",
    "os.makedirs(workdir, exist_ok=True)\n",
    "\n",
    "print('Working directory:', workdir)\n",
    "print('WandB: DESACTIVE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb79d1a6",
   "metadata": {
    "id": "fb79d1a6"
   },
   "source": [
    "## Chargement des datasets et analyse\n",
    "\n",
    "Charge les datasets (train_set.csv, test_set.csv) et affiche les statistiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87de4972",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "87de4972",
    "outputId": "b6083e70-468d-4b5c-c0c5-3cd0c15dbedf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (8000, 3)\n",
      "Test shape: (1977, 3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 8000,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8000,\n        \"samples\": [\n          \"comment obtenir un billet lille moissac ?\",\n          \"Je rentre \\u00e0 Montb\\u00e9liard depuis S\\u00e8m\\u00e8-Podji.\",\n          \"bahbah\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"intent\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"TRIP\",\n          \"NOT_TRIP\",\n          \"NOT_FRENCH\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"entities\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3596,\n        \"samples\": [\n          \"[{\\\"start\\\": 28, \\\"end\\\": 35, \\\"label\\\": \\\"Departure\\\"}, {\\\"start\\\": 41, \\\"end\\\": 45, \\\"label\\\": \\\"Destination\\\"}]\",\n          \"[{\\\"start\\\": 39, \\\"end\\\": 47, \\\"label\\\": \\\"Departure\\\"}, {\\\"start\\\": 56, \\\"end\\\": 65, \\\"label\\\": \\\"Destination\\\"}]\",\n          \"[{\\\"start\\\": 38, \\\"end\\\": 57, \\\"label\\\": \\\"Departure\\\"}, {\\\"start\\\": 60, \\\"end\\\": 67, \\\"label\\\": \\\"Destination\\\"}]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "train_df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-04fcfb1f-ed23-44ff-a389-3f32b7416cdb\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>intent</th>\n",
       "      <th>entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ein Zug nach Stuttgart, bitte</td>\n",
       "      <td>NOT_FRENCH</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S'il vous plaît, pourrais-je avoir un trajet M...</td>\n",
       "      <td>TRIP</td>\n",
       "      <td>[{\"start\": 45, \"end\": 54, \"label\": \"Departure\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pouvez-vous me trouver un train de Grenoble à ...</td>\n",
       "      <td>TRIP</td>\n",
       "      <td>[{\"start\": 35, \"end\": 43, \"label\": \"Departure\"...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-04fcfb1f-ed23-44ff-a389-3f32b7416cdb')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-04fcfb1f-ed23-44ff-a389-3f32b7416cdb button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-04fcfb1f-ed23-44ff-a389-3f32b7416cdb');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-f3833783-5e05-4644-9ee8-173eb5904645\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f3833783-5e05-4644-9ee8-173eb5904645')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-f3833783-5e05-4644-9ee8-173eb5904645 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                                text      intent  \\\n",
       "0                      Ein Zug nach Stuttgart, bitte  NOT_FRENCH   \n",
       "1  S'il vous plaît, pourrais-je avoir un trajet M...        TRIP   \n",
       "2  Pouvez-vous me trouver un train de Grenoble à ...        TRIP   \n",
       "\n",
       "                                            entities  \n",
       "0                                                 []  \n",
       "1  [{\"start\": 45, \"end\": 54, \"label\": \"Departure\"...  \n",
       "2  [{\"start\": 35, \"end\": 43, \"label\": \"Departure\"...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_path = os.path.join(workdir, 'train_set.csv')\n",
    "test_path = os.path.join(workdir, 'test_set.csv')\n",
    "\n",
    "# Verification existence\n",
    "for p in [train_path, test_path]:\n",
    "    if not os.path.exists(p):\n",
    "        print(f'ERREUR: Fichier non trouve: {p}')\n",
    "        raise FileNotFoundError(p)\n",
    "\n",
    "# Chargement\n",
    "train_df = pd.read_csv(train_path, encoding='utf-8')\n",
    "test_df = pd.read_csv(test_path, encoding='utf-8')\n",
    "\n",
    "print(f'Train shape: {train_df.shape}')\n",
    "print(f'Test shape: {test_df.shape}')\n",
    "\n",
    "print('\\nDistribution des classes (Train):')\n",
    "print(train_df['intent'].value_counts())\n",
    "print(f'\\nPourcentages:')\n",
    "print(train_df['intent'].value_counts(normalize=True).apply(lambda x: f'{x:.2%}'))\n",
    "\n",
    "display(train_df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fd1ddd",
   "metadata": {
    "id": "94fd1ddd"
   },
   "source": [
    "## Preprocessing et parsing des entities\n",
    "\n",
    "Nettoie les donnees et parse les annotations JSON pour le NER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659b0858",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "659b0858",
    "outputId": "b53120e4-d292-460e-c818-f9eff77f979e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels distribution (train):\n",
      "intent\n",
      "TRIP          5200\n",
      "NOT_TRIP      1120\n",
      "NOT_FRENCH     960\n",
      "UNKNOWN        720\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Bonjour, je compte faire le trajet vendredi de Argentan \\u00e0 Brest pour un rendez-vous.\",\n          \"\\u00c0 quelle heure y a-t-il des trains de Martigues \\u00e0 Mont\\u00e9limar ?\",\n          \"Billet Les Sables-d'Olonne Ch\\u00e2teau-Chinon\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"intent\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"NOT_FRENCH\",\n          \"TRIP\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-0238fc7b-585b-4d10-956e-1b7c0f3a4b1f\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4740</th>\n",
       "      <td>Bonjour, je compte faire le trajet vendredi de...</td>\n",
       "      <td>TRIP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5606</th>\n",
       "      <td>À quelle heure y a-t-il des trains de Martigue...</td>\n",
       "      <td>TRIP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4824</th>\n",
       "      <td>Comment aller de Malanville à Caen ?</td>\n",
       "      <td>TRIP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4205</th>\n",
       "      <td>Is there a train to Manchester?</td>\n",
       "      <td>NOT_FRENCH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3228</th>\n",
       "      <td>de Semur-en-Auxois à Dreux</td>\n",
       "      <td>TRIP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2745</th>\n",
       "      <td>Billet Les Sables-d'Olonne Château-Chinon</td>\n",
       "      <td>TRIP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0238fc7b-585b-4d10-956e-1b7c0f3a4b1f')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-0238fc7b-585b-4d10-956e-1b7c0f3a4b1f button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-0238fc7b-585b-4d10-956e-1b7c0f3a4b1f');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-8becfd44-9172-4619-9e1e-e17a688401f3\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8becfd44-9172-4619-9e1e-e17a688401f3')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-8becfd44-9172-4619-9e1e-e17a688401f3 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                                   text      intent\n",
       "4740  Bonjour, je compte faire le trajet vendredi de...        TRIP\n",
       "5606  À quelle heure y a-t-il des trains de Martigue...        TRIP\n",
       "4824               Comment aller de Malanville à Caen ?        TRIP\n",
       "4205                    Is there a train to Manchester?  NOT_FRENCH\n",
       "3228                         de Semur-en-Auxois à Dreux        TRIP\n",
       "2745          Billet Les Sables-d'Olonne Château-Chinon        TRIP"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Nettoyer les colonnes necessaires\n",
    "train_df = train_df[['text', 'intent', 'entities']].dropna(subset=['text', 'intent']).reset_index(drop=True)\n",
    "test_df = test_df[['text', 'intent', 'entities']].dropna(subset=['text', 'intent']).reset_index(drop=True)\n",
    "\n",
    "def parse_entities_field(row):\n",
    "    \"\"\"Parse la colonne entities (JSON) et valide.\"\"\"\n",
    "    try:\n",
    "        ents = json.loads(row['entities']) if pd.notna(row['entities']) else []\n",
    "    except:\n",
    "        ents = []\n",
    "    \n",
    "    valid = []\n",
    "    txt = row.get('text', '')\n",
    "    for ent in ents:\n",
    "        if isinstance(ent, dict) and 'start' in ent and 'end' in ent and 'label' in ent:\n",
    "            if 0 <= ent['start'] < ent['end'] <= len(txt):\n",
    "                valid.append(ent)\n",
    "    return valid\n",
    "\n",
    "# Parser les entities\n",
    "train_df['parsed_entities'] = train_df.apply(parse_entities_field, axis=1)\n",
    "test_df['parsed_entities'] = test_df.apply(parse_entities_field, axis=1)\n",
    "\n",
    "print('Entities parsees avec succes!')\n",
    "print(f'\\nExemple TRIP avec entities:')\n",
    "trip_ex = train_df[train_df['intent'] == 'TRIP'].iloc[0]\n",
    "print(f'  Texte: {trip_ex[\"text\"]}')\n",
    "print(f'  Entities: {trip_ex[\"parsed_entities\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kJ4w-8felakS",
   "metadata": {
    "id": "kJ4w-8felakS"
   },
   "source": [
    "## Preparation des datasets HuggingFace pour Intent Classification\n",
    "\n",
    "Convertit les DataFrames en datasets HuggingFace et encode les labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "p0LqD6INj2eo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p0LqD6INj2eo",
    "outputId": "f71bcf22-eedb-4648-de7b-ae7bfc47f72d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de villes dans le gazetteer: 763\n",
      "['# === FRANCE - GRANDES VILLES ET PRÉFECTURES ===', 'Paris', 'Marseille', 'Lyon', 'Toulouse', 'Nice', 'Nantes', 'Strasbourg', 'Montpellier', 'Bordeaux', 'Lille', 'Rennes', 'Reims', 'Le Havre', 'Saint-Étienne', 'Toulon', 'Grenoble', 'Dijon', 'Angers', 'Nîmes']\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encoder les labels d'intent\n",
    "label_encoder = LabelEncoder()\n",
    "all_intents = list(set(list(train_df['intent'].unique()) + list(test_df['intent'].unique())))\n",
    "label_encoder.fit(all_intents)\n",
    "\n",
    "print('Classes d\\'intent:')\n",
    "for i, label in enumerate(label_encoder.classes_):\n",
    "    print(f'  {i}: {label}')\n",
    "\n",
    "# Creer les datasets HuggingFace\n",
    "train_df['label'] = label_encoder.transform(train_df['intent'])\n",
    "test_df['label'] = label_encoder.transform(test_df['intent'])\n",
    "\n",
    "intent_train_dataset = Dataset.from_pandas(train_df[['text', 'label']])\n",
    "intent_test_dataset = Dataset.from_pandas(test_df[['text', 'label']])\n",
    "\n",
    "print(f'\\nIntent datasets crees:')\n",
    "print(f'  Train: {len(intent_train_dataset)} exemples')\n",
    "print(f'  Test: {len(intent_test_dataset)} exemples')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_pcysJy-l4rE",
   "metadata": {
    "id": "_pcysJy-l4rE"
   },
   "source": [
    "## Fine-Tuning Intent Classification avec CamemBERT\n",
    "\n",
    "Entrainement du modele CamemBERT pour la classification d'intent.\n",
    "\n",
    "**Ameliorations clees** :\n",
    "- Comprehension semantique (vs TF-IDF)\n",
    "- Gestion des langues etrangeres\n",
    "- Transfer learning depuis modele pre-entraine francais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nLeGKc94j8Tw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nLeGKc94j8Tw",
    "outputId": "8dde73e3-ea78-4a4e-d19f-1feca0f5db00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['NOT_FRENCH', 'NOT_TRIP', 'TRIP', 'UNKNOWN']\n",
      "Distribution dans le train:\n",
      "intent\n",
      "TRIP          0.65\n",
      "NOT_TRIP      0.14\n",
      "NOT_FRENCH    0.12\n",
      "UNKNOWN       0.09\n",
      "Name: proportion, dtype: float64\n",
      "TF-IDF matrix shape: (8000, 3147)\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import torch.nn as nn\n",
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('camembert-base')\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples['text'],\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "\n",
    "print('Tokenization...')\n",
    "tokenized_train = intent_train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_test = intent_test_dataset.map(tokenize_function, batched=True)\n",
    "print('Tokenization terminee!')\n",
    "\n",
    "# Modele avec dropout augmente\n",
    "num_labels = len(label_encoder.classes_)\n",
    "intent_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    'camembert-base',\n",
    "    num_labels=num_labels,\n",
    "    id2label={i: label for i, label in enumerate(label_encoder.classes_)},\n",
    "    label2id={label: i for i, label in enumerate(label_encoder.classes_)},\n",
    "    hidden_dropout_prob=0.4,\n",
    "    attention_probs_dropout_prob=0.4,\n",
    "    classifier_dropout=0.4\n",
    ")\n",
    "\n",
    "# Class weights\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_df['label']),\n",
    "    y=train_df['label']\n",
    ")\n",
    "\n",
    "print('\\nClass weights:')\n",
    "for label, weight in zip(label_encoder.classes_, class_weights):\n",
    "    print(f'  {label}: {weight:.3f}')\n",
    "\n",
    "# Trainer avec weighted loss (CORRIGE pour nouvelle API Transformers)\n",
    "class WeightedTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        \n",
    "        weight_tensor = torch.tensor(class_weights, dtype=torch.float).to(logits.device)\n",
    "        loss_fct = nn.CrossEntropyLoss(weight=weight_tensor)\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        \n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "# Metriques\n",
    "accuracy_metric = evaluate.load('accuracy')\n",
    "f1_metric = evaluate.load('f1')\n",
    "\n",
    "def compute_intent_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "    \n",
    "    accuracy = (predictions == labels).mean()\n",
    "    f1_macro = f1_score(labels, predictions, average='macro')\n",
    "    f1_per_class = f1_score(labels, predictions, average=None)\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': float(accuracy),\n",
    "        'f1_macro': float(f1_macro)\n",
    "    }\n",
    "    \n",
    "    for i, label in enumerate(label_encoder.classes_):\n",
    "        metrics[f'f1_{label}'] = float(f1_per_class[i])\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Training arguments optimises\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=os.path.join(workdir, 'models/intent_classifier'),\n",
    "    num_train_epochs=6,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    learning_rate=8e-6,\n",
    "    weight_decay=0.03,\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='f1_macro',\n",
    "    logging_steps=50,\n",
    "    warmup_steps=300,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    push_to_hub=False,\n",
    "    report_to='none',\n",
    "    gradient_accumulation_steps=2,\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "intent_trainer = WeightedTrainer(\n",
    "    model=intent_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_intent_metrics\n",
    ")\n",
    "\n",
    "print('\\n' + '='*70)\n",
    "print('DEBUT DU FINE-TUNING AMELIORE')\n",
    "print('='*70)\n",
    "\n",
    "intent_trainer.train()\n",
    "\n",
    "print('\\nFine-tuning termine!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cqQbXq_kmAA1",
   "metadata": {
    "id": "cqQbXq_kmAA1"
   },
   "source": [
    "## Evaluation du modele Intent Classification\n",
    "\n",
    "Evalue le modele sur le test set avec metriques detaillees et matrice de confusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "l7VbC8xTkAc8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l7VbC8xTkAc8",
    "outputId": "d7d72ef1-c4be-4fc2-f7c0-2f4e3444d7a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement du classifieur existant depuis Drive...\n",
      "Accuracy: 0.9994941831057157\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  NOT_FRENCH       1.00      1.00      1.00       221\n",
      "    NOT_TRIP       1.00      1.00      1.00       156\n",
      "        TRIP       1.00      1.00      1.00      1400\n",
      "     UNKNOWN       1.00      0.99      1.00       200\n",
      "\n",
      "    accuracy                           1.00      1977\n",
      "   macro avg       1.00      1.00      1.00      1977\n",
      "weighted avg       1.00      1.00      1.00      1977\n",
      "\n",
      "\n",
      "Classes vues par le modèle : ['NOT_FRENCH' 'NOT_TRIP' 'TRIP' 'UNKNOWN']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Evaluer sur le test set\n",
    "eval_results = intent_trainer.evaluate()\n",
    "\n",
    "print('='*70)\n",
    "print('RESULTATS SUR LE TEST SET')\n",
    "print('='*70)\n",
    "for key, value in eval_results.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f'  {key}: {value:.4f}')\n",
    "\n",
    "# Predictions detaillees\n",
    "predictions = intent_trainer.predict(tokenized_test)\n",
    "predicted_labels = np.argmax(predictions.predictions, axis=-1)\n",
    "true_labels = predictions.label_ids\n",
    "\n",
    "\n",
    "# Ajouter post-processing\n",
    "def post_process_prediction(text, predicted_intent):\n",
    "    \"\"\"\n",
    "    Corrige les predictions aberrantes avec regles heuristiques.\n",
    "    \"\"\"\n",
    "    text_lower = text.lower().strip()\n",
    "    \n",
    "    # Detection langue\n",
    "    try:\n",
    "        from langdetect import detect\n",
    "        lang = detect(text) if len(text) >= 3 else 'unknown'\n",
    "    except:\n",
    "        lang = 'fr'  # Par defaut francais\n",
    "    \n",
    "    # REGLE 1: Langue non-francaise\n",
    "    english_markers = ['i ', 'you ', 'the ', 'is ', 'are ', 'have ', 'do ', 'can ', 'hello', 'please']\n",
    "    spanish_markers = ['el ', 'la ', 'los ', 'de ', 'que ', 'por ', 'para ', 'bueno', 'gracias']\n",
    "    german_markers = ['der ', 'die ', 'das ', 'ist ', 'ich ', 'sie ', 'haben ', 'guten', 'danke']\n",
    "    \n",
    "    if (lang not in ['fr', 'unknown']) or \\\n",
    "       any(marker in text_lower for marker in english_markers + spanish_markers + german_markers):\n",
    "        if predicted_intent != 'NOT_FRENCH':\n",
    "            return 'NOT_FRENCH'\n",
    "    \n",
    "    # REGLE 2: Mots-cles NOT_TRIP\n",
    "    not_trip_keywords = [\n",
    "        'merci', 'remercie', 'confirme', 'email', 'reunion', 'document',\n",
    "        'rapport', 'felicitation', 'bravo', 'compte-rendu', 'transferer'\n",
    "    ]\n",
    "    if any(kw in text_lower for kw in not_trip_keywords):\n",
    "        trip_keywords = ['billet', 'train', 'aller', 'retour', 'trajet']\n",
    "        has_trip = any(kw in text_lower for kw in trip_keywords)\n",
    "        if not has_trip and predicted_intent == 'TRIP':\n",
    "            return 'NOT_TRIP'\n",
    "    \n",
    "    # REGLE 3: Texte incomprehensible (tres court, pas de mots francais)\n",
    "    if len(text_lower) < 15 and lang == 'unknown':\n",
    "        words = text_lower.split()\n",
    "        if len(words) <= 3:\n",
    "            # Verifier si ce sont des mots francais reconnaissables\n",
    "            french_common = ['de', 'a', 'le', 'la', 'pour', 'je', 'tu', 'il']\n",
    "            if not any(word in french_common for word in words):\n",
    "                if predicted_intent != 'UNKNOWN':\n",
    "                    return 'UNKNOWN'\n",
    "    \n",
    "    # REGLE 4: Format \"Ville1 Ville2\" = TRIP\n",
    "    words = text_lower.split()\n",
    "    if len(words) == 2 and len(text) < 50:\n",
    "        # Verifier si ce sont deux noms propres (majuscules)\n",
    "        if text.split()[0][0].isupper() and text.split()[1][0].isupper():\n",
    "            if predicted_intent != 'TRIP':\n",
    "                return 'TRIP'\n",
    "    \n",
    "    # REGLE 5: Presence \"de X a Y\" ou \"X Y\" = TRIP\n",
    "    if ('de ' in text_lower and ' a ' in text_lower) or \\\n",
    "       ('de ' in text_lower and ' vers ' in text_lower) or \\\n",
    "       (' pour ' in text_lower and len(words) < 10):\n",
    "        trip_keywords = ['billet', 'train', 'horaire', 'tarif']\n",
    "        not_trip_keywords_strict = ['merci', 'document', 'rapport']\n",
    "        has_not_trip = any(kw in text_lower for kw in not_trip_keywords_strict)\n",
    "        if not has_not_trip and predicted_intent != 'TRIP':\n",
    "            return 'TRIP'\n",
    "    \n",
    "    return predicted_intent\n",
    "\n",
    "# Appliquer post-processing\n",
    "test_df_eval = test_df.copy()\n",
    "test_df_eval['predicted_label'] = predicted_labels\n",
    "test_df_eval['predicted_intent'] = label_encoder.inverse_transform(predicted_labels)\n",
    "\n",
    "corrected_intents = []\n",
    "for idx, row in test_df_eval.iterrows():\n",
    "    corrected = post_process_prediction(row['text'], row['predicted_intent'])\n",
    "    corrected_intents.append(corrected)\n",
    "\n",
    "test_df_eval['corrected_intent'] = corrected_intents\n",
    "test_df_eval['corrected_label'] = label_encoder.transform(corrected_intents)\n",
    "\n",
    "# Comparer\n",
    "accuracy_before = (test_df_eval['label'] == test_df_eval['predicted_label']).mean()\n",
    "accuracy_after = (test_df_eval['label'] == test_df_eval['corrected_label']).mean()\n",
    "\n",
    "print(f'\\\\nAccuracy avant post-processing: {accuracy_before:.4f}')\n",
    "print(f'Accuracy apres post-processing: {accuracy_after:.4f}')\n",
    "print(f'Amelioration: {(accuracy_after - accuracy_before):.4f} ({(accuracy_after/accuracy_before - 1)*100:+.2f}%)')\n",
    "\n",
    "# Classification report apres PP\n",
    "from sklearn.metrics import classification_report\n",
    "print('\\\\n' + '='*70)\n",
    "print('CLASSIFICATION REPORT APRES POST-PROCESSING')\n",
    "print('='*70)\n",
    "print(classification_report(\n",
    "    test_df_eval['label'],\n",
    "    test_df_eval['corrected_label'],\n",
    "    target_names=label_encoder.classes_,\n",
    "    digits=4\n",
    "))\n",
    "\n",
    "# Classification report\n",
    "print('\\n' + '='*70)\n",
    "print('CLASSIFICATION REPORT')\n",
    "print('='*70)\n",
    "print(classification_report(\n",
    "    true_labels,\n",
    "    predicted_labels,\n",
    "    target_names=label_encoder.classes_,\n",
    "    digits=4\n",
    "))\n",
    "\n",
    "# Matrice de confusion\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap='Blues',\n",
    "    xticklabels=label_encoder.classes_,\n",
    "    yticklabels=label_encoder.classes_\n",
    ")\n",
    "plt.title('Matrice de Confusion - Intent Classification')\n",
    "plt.ylabel('Vraie Classe')\n",
    "plt.xlabel('Classe Predite')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Sauvegarder le modele\n",
    "model_path = os.path.join(workdir, 'models/intent_classifier_best')\n",
    "intent_trainer.save_model(model_path)\n",
    "tokenizer.save_pretrained(model_path)\n",
    "\n",
    "print(f'\\nModele sauvegarde dans: {model_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LBmglzxGmgRH",
   "metadata": {
    "id": "LBmglzxGmgRH"
   },
   "source": [
    "## Preparation du dataset NER (Token Classification)\n",
    "\n",
    "Conversion des annotations en format BIO pour le NER contextuel avec Transformers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dicWkLvakBWQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dicWkLvakBWQ",
    "outputId": "a5b169cf-8418-42b8-a875-9d35e23f41ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Je voudrais un billet Toulouse Paris. -> ['Toulouse', 'Toul', 'Paris']\n",
      "Aller de Bordeaux vers Nantes -> ['Bordeaux', 'Nantes']\n",
      "Bonjour, pouvez-vous m aider? -> []\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Tokenizer rapide pour NER\n",
    "tokenizer_fast = AutoTokenizer.from_pretrained('camembert-base', use_fast=True)\n",
    "\n",
    "# Labels NER en format BIO\n",
    "ner_labels = ['O', 'B-Departure', 'I-Departure', 'B-Destination', 'I-Destination']\n",
    "label2id = {label: i for i, label in enumerate(ner_labels)}\n",
    "id2label = {i: label for label, i in label2id.items()}\n",
    "\n",
    "print('Labels NER:')\n",
    "for label_id, label_name in id2label.items():\n",
    "    print(f'  {label_id}: {label_name}')\n",
    "\n",
    "def convert_to_bio_tags(text, entities):\n",
    "    \"\"\"Convertit les annotations en tags BIO pour chaque token.\"\"\"\n",
    "    encoding = tokenizer_fast(\n",
    "        text,\n",
    "        return_offsets_mapping=True,\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        padding='max_length'\n",
    "    )\n",
    "    \n",
    "    offset_mapping = encoding['offset_mapping']\n",
    "    labels = ['O'] * len(offset_mapping)\n",
    "    \n",
    "    for entity in entities:\n",
    "        start_char = entity['start']\n",
    "        end_char = entity['end']\n",
    "        entity_label = entity['label']\n",
    "        \n",
    "        token_indices = []\n",
    "        for idx, (token_start, token_end) in enumerate(offset_mapping):\n",
    "            if token_start == token_end == 0:\n",
    "                continue\n",
    "            if not (token_end <= start_char or token_start >= end_char):\n",
    "                token_indices.append(idx)\n",
    "        \n",
    "        if token_indices:\n",
    "            labels[token_indices[0]] = f'B-{entity_label}'\n",
    "            for idx in token_indices[1:]:\n",
    "                labels[idx] = f'I-{entity_label}'\n",
    "    \n",
    "    label_ids = [label2id.get(label, 0) for label in labels]\n",
    "    \n",
    "    return {\n",
    "        'input_ids': encoding['input_ids'],\n",
    "        'attention_mask': encoding['attention_mask'],\n",
    "        'labels': label_ids\n",
    "    }\n",
    "\n",
    "# Preparer les datasets NER\n",
    "print('\\nConversion en format BIO...')\n",
    "ner_train_data = []\n",
    "for _, row in train_df.iterrows():\n",
    "    entities = row['parsed_entities'] if row['intent'] == 'TRIP' else []\n",
    "    ner_example = convert_to_bio_tags(row['text'], entities)\n",
    "    ner_train_data.append(ner_example)\n",
    "\n",
    "ner_test_data = []\n",
    "for _, row in test_df.iterrows():\n",
    "    entities = row['parsed_entities'] if row['intent'] == 'TRIP' else []\n",
    "    ner_example = convert_to_bio_tags(row['text'], entities)\n",
    "    ner_test_data.append(ner_example)\n",
    "\n",
    "ner_train_dataset = Dataset.from_list(ner_train_data)\n",
    "ner_test_dataset = Dataset.from_list(ner_test_data)\n",
    "\n",
    "print(f'Datasets NER crees:')\n",
    "print(f'  Train: {len(ner_train_dataset)} exemples')\n",
    "print(f'  Test: {len(ner_test_dataset)} exemples')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3FE4tUknFEE",
   "metadata": {
    "id": "a3FE4tUknFEE"
   },
   "source": [
    "## Fine-Tuning NER avec CamemBERT\n",
    "\n",
    "Entrainement du modele NER pour extraire Departure et Destination de maniere contextuelle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "S2CLKi4SkGiq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S2CLKi4SkGiq",
    "outputId": "731ec4b1-20d0-4741-ecfc-f59b1ef229e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,Toulouse,Paris\n",
      "2,NOT_TRIP\n",
      "3,NOT_FRENCH\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoModelForTokenClassification,\n",
    "    DataCollatorForTokenClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "import evaluate\n",
    "\n",
    "# Charger le modele CamemBERT pour Token Classification\n",
    "ner_model = AutoModelForTokenClassification.from_pretrained(\n",
    "    'camembert-base',\n",
    "    num_labels=len(ner_labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "# Data collator\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer_fast)\n",
    "\n",
    "# Metrique seqeval\n",
    "seqeval_metric = evaluate.load('seqeval')\n",
    "\n",
    "def compute_ner_metrics(eval_pred):\n",
    "    \"\"\"Calcule les metriques NER avec seqeval.\"\"\"\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "    \n",
    "    for pred_seq, label_seq in zip(predictions, labels):\n",
    "        true_tags = []\n",
    "        pred_tags = []\n",
    "        \n",
    "        for pred_id, label_id in zip(pred_seq, label_seq):\n",
    "            if label_id != -100:\n",
    "                true_tags.append(id2label[label_id])\n",
    "                pred_tags.append(id2label[pred_id])\n",
    "        \n",
    "        true_labels.append(true_tags)\n",
    "        pred_labels.append(pred_tags)\n",
    "    \n",
    "    results = seqeval_metric.compute(predictions=pred_labels, references=true_labels)\n",
    "    \n",
    "    return {\n",
    "        'precision': results['overall_precision'],\n",
    "        'recall': results['overall_recall'],\n",
    "        'f1': results['overall_f1'],\n",
    "        'accuracy': results['overall_accuracy']\n",
    "    }\n",
    "\n",
    "# Arguments d'entrainement\n",
    "ner_training_args = TrainingArguments(\n",
    "    output_dir=os.path.join(workdir, 'models/ner_model'),\n",
    "    num_train_epochs=4,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=3e-5,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='f1',\n",
    "    logging_steps=100,\n",
    "    warmup_steps=200,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    push_to_hub=False,\n",
    "    report_to='none',\n",
    ")\n",
    "\n",
    "# Creer le Trainer\n",
    "ner_trainer = Trainer(\n",
    "    model=ner_model,\n",
    "    args=ner_training_args,\n",
    "    train_dataset=ner_train_dataset,\n",
    "    eval_dataset=ner_test_dataset,\n",
    "    tokenizer=tokenizer_fast,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_ner_metrics\n",
    ")\n",
    "\n",
    "print('\\n' + '='*70)\n",
    "print('DEBUT DU FINE-TUNING NER')\n",
    "print('='*70)\n",
    "\n",
    "# Entrainer le modele\n",
    "ner_trainer.train()\n",
    "\n",
    "print('\\nFine-tuning NER termine!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RL0en7minNy9",
   "metadata": {
    "id": "RL0en7minNy9"
   },
   "source": [
    "## Evaluation du modele NER\n",
    "\n",
    "Evalue le modele NER avec metriques detaillees par entite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Bym2BeNdkJnS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bym2BeNdkJnS",
    "outputId": "31bbbe34-4d83-4150-f344-ca956eaf177b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sortie écrite dans /content/drive/MyDrive/dataset/predicted_output.txt\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import classification_report as seqeval_report\n",
    "\n",
    "# Evaluer sur le test set\n",
    "ner_eval_results = ner_trainer.evaluate()\n",
    "\n",
    "print('='*70)\n",
    "print('RESULTATS NER SUR LE TEST SET')\n",
    "print('='*70)\n",
    "for key, value in ner_eval_results.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f'  {key}: {value:.4f}')\n",
    "\n",
    "# Predictions detaillees\n",
    "ner_predictions = ner_trainer.predict(ner_test_dataset)\n",
    "predicted_logits = ner_predictions.predictions\n",
    "predicted_labels = np.argmax(predicted_logits, axis=-1)\n",
    "true_labels = ner_predictions.label_ids\n",
    "\n",
    "# Convertir en tags pour seqeval\n",
    "true_tags_list = []\n",
    "pred_tags_list = []\n",
    "\n",
    "for pred_seq, label_seq in zip(predicted_labels, true_labels):\n",
    "    true_tags = []\n",
    "    pred_tags = []\n",
    "    \n",
    "    for pred_id, label_id in zip(pred_seq, label_seq):\n",
    "        if label_id != -100:\n",
    "            true_tags.append(id2label[label_id])\n",
    "            pred_tags.append(id2label[pred_id])\n",
    "    \n",
    "    true_tags_list.append(true_tags)\n",
    "    pred_tags_list.append(pred_tags)\n",
    "\n",
    "# Classification report detaille\n",
    "print('\\n' + '='*70)\n",
    "print('CLASSIFICATION REPORT NER (par entite)')\n",
    "print('='*70)\n",
    "print(seqeval_report(true_tags_list, pred_tags_list, digits=4))\n",
    "\n",
    "# Sauvegarder le modele\n",
    "ner_model_path = os.path.join(workdir, 'models/ner_model_best')\n",
    "ner_trainer.save_model(ner_model_path)\n",
    "tokenizer_fast.save_pretrained(ner_model_path)\n",
    "\n",
    "print(f'\\nModele NER sauvegarde dans: {ner_model_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-HcZC5OrnX4s",
   "metadata": {
    "id": "-HcZC5OrnX4s"
   },
   "source": [
    "## Pipeline d'inference complet avec Transformers\n",
    "\n",
    "Combine Intent Classification + NER pour predictions completes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rAd-aurykPEa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rAd-aurykPEa",
    "outputId": "b3b56ce5-9074-4dfb-ee09-d8e4a82597ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifacts saved:\n",
      "{'vectorizer_path': '/content/drive/MyDrive/dataset/tfidf_vectorizer.joblib', 'clf_path': '/content/drive/MyDrive/dataset/baseline_intent_clf.joblib', 'label_encoder_path': '/content/drive/MyDrive/dataset/label_encoder.joblib'}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Charger les pipelines\n",
    "print('Chargement des modeles...')\n",
    "\n",
    "intent_model_path = os.path.join(workdir, 'models/intent_classifier_best')\n",
    "ner_model_path = os.path.join(workdir, 'models/ner_model_best')\n",
    "\n",
    "intent_pipeline = pipeline(\n",
    "    'text-classification',\n",
    "    model=intent_model_path,\n",
    "    tokenizer=intent_model_path,\n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")\n",
    "\n",
    "ner_pipeline = pipeline(\n",
    "    'token-classification',\n",
    "    model=ner_model_path,\n",
    "    tokenizer=ner_model_path,\n",
    "    aggregation_strategy='simple',\n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")\n",
    "\n",
    "print('Pipelines charges!')\n",
    "\n",
    "def predict_travel_order(sentence_id, text):\n",
    "    \"\"\"Pipeline complet : Intent + NER\"\"\"\n",
    "    # 1. Predire l'intent\n",
    "    intent_result = intent_pipeline(text)[0]\n",
    "    predicted_intent = intent_result['label']\n",
    "    confidence = intent_result['score']\n",
    "    \n",
    "    # 2. Si pas TRIP, retourner l'intent\n",
    "    if predicted_intent != 'TRIP':\n",
    "        return f\"{sentence_id},{predicted_intent}\", confidence\n",
    "    \n",
    "    # 3. Si TRIP, extraire les entites\n",
    "    ner_results = ner_pipeline(text)\n",
    "    \n",
    "    departure = None\n",
    "    destination = None\n",
    "    \n",
    "    for entity in ner_results:\n",
    "        entity_label = entity.get('entity_group', entity.get('entity'))\n",
    "        word = entity['word'].replace('▁', ' ').strip()\n",
    "        \n",
    "        if 'Departure' in entity_label and not departure:\n",
    "            departure = word\n",
    "        elif 'Destination' in entity_label and not destination:\n",
    "            destination = word\n",
    "    \n",
    "    if departure and destination:\n",
    "        return f\"{sentence_id},{departure},{destination}\", confidence\n",
    "    else:\n",
    "        return f\"{sentence_id},UNKNOWN\", confidence\n",
    "\n",
    "# Tester sur les exemples problematiques mentionnes\n",
    "print('\\n' + '='*70)\n",
    "print('TESTS SUR EXEMPLES PROBLEMATIQUES')\n",
    "print('='*70)\n",
    "\n",
    "test_examples = [\n",
    "    (\"4740\", \"Bonjour, je compte faire le trajet vendredi de Cotonou à Porto-Novo\"),\n",
    "    (\"5606\", \"À quelle heure y a-t-il des trains de Martigues à Lyon ?\"),\n",
    "    (\"4824\", \"Comment aller de Malanville à Caen ?\"),\n",
    "    (\"4205\", \"Is there a train to Manchester?\"),\n",
    "    (\"3228\", \"de Semur-en-Auxois à Dreux\"),\n",
    "    (\"2745\", \"Billet Les Sables-d'Olonne Château-Chinon\")\n",
    "]\n",
    "\n",
    "for sid, text in test_examples:\n",
    "    result, conf = predict_travel_order(sid, text)\n",
    "    print(f'\\n{sid}: {text}')\n",
    "    print(f'  -> Prediction: {result}')\n",
    "    print(f'  -> Confiance: {conf:.2%}')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
